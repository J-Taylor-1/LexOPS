lexops <- tibble(
  string = dat$string,
  CMU.pr1_1letter = dat$cmu.pr1_pronun_1letter,
  CMU.pr2_1letter = dat$cmu.pr2_pronun_1letter,
  CMU.pr3_1letter = dat$cmu.pr3_pronun_1letter,
  CMU.pr4_1letter = dat$cmu.pr4_pronun_1letter,
  CMU.PrN = dat$cmu.alternatives,
  Zipf.SUBTLEX_UK = dat$subtlex_uk.zipf,
  Zipf.SUBTLEX_US = dat$subtlex_us.zipf,
  Zipf.BNC.Spoken = dat$bnc.sZipf,
  Zipf.BNC.Written = dat$bnc.wZipf,
  Zipf.Mean = dat$Mean.Zipf,
  fpmw.SUBTLEX_UK = dat$subtlex_uk.fpmw,
  fpmw.SUBTLEX_US = dat$subtlex_us.fpmw,
  fpmw.BNC.Spoken = dat$bnc.sFpmw,
  fpmw.BNC.Written = dat$bnc.wFpmw,
  fpmw.Mean = dat$Mean.fpmw,
  PoS.SUBTLEX_UK = dat$subtlex_uk.DomPoS,
  PoS.BNC.Written = dat$bnc.wDomPoS,
  PoS.BNC.Spoken = dat$bnc.sDomPoS,
  PoS.ELP = dat$elp.DomPoS,
  Length = dat$Length,
  BG.SUBTLEX_UK = dat$subtlex_uk.bg,
  BG.SUBTLEX_US = dat$subtlex_us.bg,
  BG.BNC.Spoken = dat$bnc.sbg,
  BG.BNC.Written = dat$bnc.wbg,
  BG.Mean = dat$Mean.bg,
  ON.OLD20 = dat$old20,
  ON.Colthearts_N = dat$coltheart.N,
  ON.Log_OLD20 = log(dat$old20),
  ON.Log_Colthearts_N = log(dat$coltheart.N),
  Syllables.Moby = dat$mhyph.syllables,
  Syllables.CMU.pr1 = dat$cmu.pr1_syllables,
  Syllables.CMU.pr2 = dat$cmu.pr2_syllables,
  Syllables.CMU.pr3 = dat$cmu.pr3_syllables,
  Syllables.CMU.pr4 = dat$cmu.pr4_syllables,
  Phonemes.CMU.pr1 = dat$cmu.pr1_N_phonemes,
  Phonemes.CMU.pr2 = dat$cmu.pr2_N_phonemes,
  Phonemes.CMU.pr3 = dat$cmu.pr3_N_phonemes,
  Phonemes.CMU.pr4 = dat$cmu.pr4_N_phonemes,
  Rhyme.CMU.pr1 = dat$cmu.pr1_rhymesound,
  Rhyme.CMU.pr2 = dat$cmu.pr2_rhymesound,
  Rhyme.CMU.pr3 = dat$cmu.pr3_rhymesound,
  Rhyme.CMU.pr4 = dat$cmu.pr4_rhymesound,
  PN.PLD20.CMU.pr1 = dat$cmu.pr1_pld20,
  PN.PLD20.CMU.pr2 = dat$cmu.pr2_pld20,
  PN.PLD20.CMU.pr3 = dat$cmu.pr3_pld20,
  PN.PLD20.CMU.pr4 = dat$cmu.pr4_pld20,
  PN.Colthearts_N.CMU.pr1 = dat$cmu.pr1_phon.coltheart.N,
  PN.Colthearts_N.CMU.pr2 = dat$cmu.pr2_phon.coltheart.N,
  PN.Colthearts_N.CMU.pr3 = dat$cmu.pr3_phon.coltheart.N,
  PN.Colthearts_N.CMU.pr4 = dat$cmu.pr4_phon.coltheart.N,
  PN.Log_PLD20.CMU.pr1 = log(dat$cmu.pr1_pld20),
  PN.Log_PLD20.CMU.pr2 = log(dat$cmu.pr2_pld20),
  PN.Log_PLD20.CMU.pr3 = log(dat$cmu.pr3_pld20),
  PN.Log_PLD20.CMU.pr4 = log(dat$cmu.pr4_pld20),
  PN.Log_Colthearts_N.CMU.pr1 = log(dat$cmu.pr1_phon.coltheart.N),
  PN.Log_Colthearts_N.CMU.pr2 = log(dat$cmu.pr2_phon.coltheart.N),
  PN.Log_Colthearts_N.CMU.pr3 = log(dat$cmu.pr3_phon.coltheart.N),
  PN.Log_Colthearts_N.CMU.pr4 = log(dat$cmu.pr4_phon.coltheart.N),
  FAM.Glasgow_Norms = dat$gn.FAM,
  FAM.Clark_and_Paivio = dat$cp.FAM,
  AoA.Kuperman = dat$kuperman.AOA,
  AoA.Glasgow_Norms = dat$gn.AOA,
  AoA.BrysbaertBiemiller = dat$bb.AOA,
  CNC.Brysbaert = dat$brysbaert.CNC,
  CNC.Glasgow_Norms = dat$gn.CNC,
  IMAG.Glasgow_Norms = dat$gn.IMAG,
  IMAG.Clark_and_Paivio = dat$cp.IMAG,
  AROU.Warriner = dat$warriner.AROU,
  AROU.Glasgow_Norms = dat$gn.AROU,
  VAL.Warriner = dat$warriner.VAL,
  VAL.Glasgow_Norms = dat$gn.VAL,
  DOM.Warriner = dat$warriner.DOM,
  DOM.Glasgow_Norms = dat$gn.DOM,
  SIZE.Glasgow_Norms = dat$gn.SIZE,
  GEND.Glasgow_Norms = dat$gn.GEND,
  HUM.EngelthalerHills = dat$eh.HUM,
  RT.BLP = dat$blp.rt,
  RT_zscore.BLP = dat$blp.rt.zscore,
  Accuracy.BLP = dat$blp.accuracy,
  Accuracy_zscore.BLP = dat$blp.accuracy.zscore,
  RT.ELP = dat$elp.rt,
  RT_zscore.ELP = dat$elp.rt.zscore,
  Accuracy.ELP = dat$elp.accuracy,
  Accuracy_zscore.ELP = dat$elp.accuracy.zscore)


# Visualilsation vector categories
vis.cats <- c('Word Frequency', 'Part of Speech', 'Length', 'Bigram Frequency', 'Orthographic Neighbourhood', 'Syllables', 'Phonemes', 'Rhyme', 'Phonological Neighbourhood', 'Familiarity', 'Age of Acquisition', 'Concreteness', 'Arousal', 'Valence', 'Dominance', 'Imageability', 'Semantic Size', 'Semantic Gender', 'Humour', 'Lexical Decision Response Time', 'Lexical Decision Accuracy')

visualise.opts <- names(lexops)[!(names(lexops) %in% c('string'))]

vis.opt.2.source <- function(x){switch(x,
                                       '(None)' = '',
                                       'Target Word' = '',
                                       'Suggested Matches' = '',
                                       'Part of Speech' = visualise.opts[grepl("PoS",visualise.opts)],
                                       'Length' = 'Length',
                                       'Syllables' = visualise.opts[grepl("Syllables",visualise.opts)],
                                       'Word Frequency' = visualise.opts[grepl("Zipf",visualise.opts) | grepl("fpmw",visualise.opts)],
                                       'Bigram Frequency' = visualise.opts[grepl("BG",visualise.opts)],
                                       'Orthographic Neighbourhood' = visualise.opts[grepl("ON",visualise.opts)],
                                       'Phonemes' = visualise.opts[grepl("Phonemes",visualise.opts)],
                                       'Rhyme' = visualise.opts[grepl("Rhyme",visualise.opts)],
                                       'Phonological Neighbourhood' = visualise.opts[grepl("PLD20",visualise.opts) | grepl("PhonColtheartN",visualise.opts)],
                                       'Familiarity' = visualise.opts[grepl("FAM",visualise.opts)],
                                       'Age of Acquisition' = visualise.opts[grepl("AoA",visualise.opts)],
                                       'Concreteness' = visualise.opts[grepl("CNC",visualise.opts)],
                                       'Arousal' = visualise.opts[grepl("AROU",visualise.opts)],
                                       'Valence' = visualise.opts[grepl("VAL",visualise.opts)],
                                       'Dominance' = visualise.opts[grepl("DOM",visualise.opts)],
                                       'Imageability' = visualise.opts[grepl("IMAG",visualise.opts)],
                                       'Semantic Size' = visualise.opts[grepl("SIZE",visualise.opts)],
                                       'Semantic Gender' = visualise.opts[grepl("GEND",visualise.opts)],
                                       'Humoour' = visualise.opts[grepl("HUM",visualise.opts)],
                                       'Lexical Decision Response Time' = visualise.opts[grepl("RT",visualise.opts)],
                                       'Lexical Decision Accuracy' = visualise.opts[grepl("Accuracy",visualise.opts)]
)}